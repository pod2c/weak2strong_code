{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53446a9-2ae4-415d-8293-c50d7119e994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U transformers accelerate datasets bitsandbytes einops wandb trl peft scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a7523-1cb1-402a-9750-ef5eae16a987",
   "metadata": {},
   "source": [
    "# 导入由弱模型标记的数据集 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c8a421-e84c-4bb1-9b6e-48b58d95abc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86759486fed2430db9caa4b763113e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"dataset_train_strong.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5758d-9090-4171-a3ab-5218870a10d0",
   "metadata": {},
   "source": [
    "# 预处理数据集，合并字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c54472-3408-4af8-a058-c8e95ccba928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_fields(example):\n",
    "    text = example['text']\n",
    "    label = example['predicted_label']\n",
    "    merged_input = f\"Text: {text}\\nLabel: {label}\"\n",
    "    return {'merged_input': merged_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c9ef33-d3ad-4d24-8483-4cd24cfaf6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f4d7cb99c54162acabca314e630417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(merge_fields, remove_columns=['text', 'predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f808ae-b207-4550-bc66-50d805ffed2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'merged_input': 'Text: \\n\\nHuman: How do I work on robotics on space shuttles?\\n\\nAssistant: What kind of work would you like to do on robotics?\\n\\nHuman: I will test them out and help to maintain them.\\n\\nAssistant: What kind of testing would you like to do?\\n\\nHuman: I would make sure they’re working properly and correctly.\\n\\nAssistant: What kind of maintenance would you like to help with?\\n\\nHuman: Maintaining the entire robotics system.\\n\\nAssistant: What specific aspect of the robotics system would you like to maintain?\\nLabel: -1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1fd23-c106-457d-b6dc-0438abb39d78",
   "metadata": {},
   "source": [
    "# 强模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87db65ad-0f54-4b9f-9916-e9ded838c7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7672bfab38944579a4e8483a4799cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_name = 'gpt2-medium'\n",
    "\n",
    "#bnb_config = BitsAndBytesConfig(\n",
    "    #load_in_4bit=True,\n",
    "    #bnb_4bit_quant_type='nf4',\n",
    "    #bnb_4bit_compute_dtype=torch.float16,\n",
    "#)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='auto',\n",
    "    #quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d0927b-421b-4d54-b06a-891f964e3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ace28b-f6c6-46e5-a16c-3aa97c287704",
   "metadata": {},
   "source": [
    "# 训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7377d9c7-6e0c-4831-a8c2-4c0519e3482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = './results1'\n",
    "per_device_train_batch_size = 4\n",
    "gradient_accumulation_steps = 4\n",
    "optim = 'paged_adamw_32bit'\n",
    "save_steps = 1000\n",
    "logging_steps = 10\n",
    "learning_rate = 2e-5\n",
    "max_grad_norm = 0.3\n",
    "max_steps = 1000\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = 'constant'\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    #fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd88b4-c934-4916-8abb-3ac222879866",
   "metadata": {},
   "source": [
    "# 训练器设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5d3a2ff-4e9a-4300-aadd-e470596ef9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f680c27878945139bc5e0ccc49eaacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "#from accelerate import Accelerator\n",
    "\n",
    "max_seq_length = 512\n",
    "\n",
    "#accelerator = Accelerator()\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    #peft_config=peft_config,\n",
    "    dataset_text_field='merged_input',\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "\n",
    "for name, module in trainer.model.named_modules():\n",
    "    if 'norm' in name:\n",
    "        module = module.to(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c747f07-277b-4656-a4fc-7d0d3068c975",
   "metadata": {},
   "source": [
    "# 强模型训练阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23fa6b5b-fe25-4db4-ac30-8611b87610bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/wandb/run-20240508_014720-bnd7j80d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s1820587/huggingface/runs/bnd7j80d' target=\"_blank\">ruby-cosmos-164</a></strong> to <a href='https://wandb.ai/s1820587/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s1820587/huggingface' target=\"_blank\">https://wandb.ai/s1820587/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s1820587/huggingface/runs/bnd7j80d' target=\"_blank\">https://wandb.ai/s1820587/huggingface/runs/bnd7j80d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 08:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.436100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.275500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.873200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.256700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.164300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.071100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.787600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.239700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.126100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.802400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.177900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.096700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.949200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.109300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.802100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.172200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.975900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.926500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.862600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.609200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.838000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.637900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.991700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.884600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.872300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.632400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.955900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.902300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.633800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.084800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.993700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.915800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.862400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.625500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.994400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.944400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.824200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.459600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.930600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.831600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.495900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.088700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.908300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.860600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.775100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.556200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.069000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.919400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.819700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.763800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.510800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.949200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.844200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.723900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.523500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=1.924448346455892, metrics={'train_runtime': 513.5424, 'train_samples_per_second': 23.367, 'train_steps_per_second': 1.46, 'total_flos': 4761869278347264.0, 'train_loss': 1.924448346455892, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f60180-5f6c-4936-abeb-582f79975406",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
    "model_to_save.save_pretrained('gpt2medium_strong_model_outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb82d10-c24d-421d-8cf6-59801d1fb33b",
   "metadata": {},
   "source": [
    "# 使用训练好的强模型在测试集上进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d0638bb-dc55-48da-9cdb-47853a8df43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 17104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17104/17104 [44:16<00:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4955\n",
      "F1 score: 0.5274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import logging\n",
    "\n",
    "# 设置日志级别为ERROR,以抑制警告信息\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# 加载微调后的tokenizer和模型\n",
    "model_path = \"gpt2medium_strong_model_outputs\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2-medium')\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto', trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 将模型移动到GPU(如果可用)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "finetuned_model.to(device)\n",
    "\n",
    "# 定义分类标签\n",
    "label_map = {0: \" No\", 1: \" Yes\"}\n",
    "\n",
    "# 加载测试数据集\n",
    "test_ds = load_dataset(\"json\", data_files=\"test_ds.jsonl\", split='train')\n",
    "\n",
    "# 对数据集进行预处理和打标签\n",
    "def preprocess_and_label(example):\n",
    "    # 对输入文本进行预处理\n",
    "    inputs = tokenizer(example[\"text\"], return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    \n",
    "    # 将输入数据移动到与模型相同的设备\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    # 使用模型进行预测\n",
    "    with torch.no_grad():\n",
    "        outputs = finetuned_model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=10, num_return_sequences=1)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # 判断生成的文本属于哪个类别\n",
    "    if label_map[0] in generated_text:\n",
    "        predicted_label = 0\n",
    "    elif label_map[1] in generated_text:\n",
    "        predicted_label = 1\n",
    "    else:\n",
    "        predicted_label = None  # 如果生成的文本不包含任何一个标签,则不考虑这个样本\n",
    "    \n",
    "    return {\"text\": example[\"text\"], \"label\": example[\"label\"], \"predicted_label\": predicted_label}\n",
    "\n",
    "# 在测试集上进行预测\n",
    "predictions = []\n",
    "labels = []\n",
    "total_examples = len(test_ds)\n",
    "print(f\"Total examples: {total_examples}\")\n",
    "\n",
    "progress_bar = tqdm(test_ds, desc=\"Evaluating\")\n",
    "\n",
    "for example in progress_bar:\n",
    "    processed_example = preprocess_and_label(example)\n",
    "    if processed_example[\"predicted_label\"] is not None:  # 只考虑有效的预测\n",
    "        predictions.append(processed_example[\"predicted_label\"])\n",
    "        labels.append(processed_example[\"label\"])\n",
    "\n",
    "# 打印最终的评估指标\n",
    "print(f\"Accuracy: {accuracy_score(labels, predictions):.4f}\")\n",
    "print(f\"F1 score: {f1_score(labels, predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce44917f-fcc5-4f8d-b630-d9592a2e1204",
   "metadata": {},
   "source": [
    "# 使用原始模型在同样的数据集上进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dffdd2de-e189-4df3-b6d6-21d36a0b9801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 17104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17104/17104 [45:06<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4982\n",
      "F1 score: 0.5284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import logging\n",
    "\n",
    "# 设置日志级别为ERROR,以抑制警告信息\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# 加载微调后的tokenizer和模型\n",
    "model_path = \"gpt2-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2-medium')\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto', trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 将模型移动到GPU(如果可用)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "finetuned_model.to(device)\n",
    "\n",
    "# 定义分类标签\n",
    "label_map = {0: \" No\", 1: \" Yes\"}\n",
    "\n",
    "# 加载测试数据集\n",
    "test_ds = load_dataset(\"json\", data_files=\"test_ds.jsonl\", split='train')\n",
    "\n",
    "# 对数据集进行预处理和打标签\n",
    "def preprocess_and_label(example):\n",
    "    # 对输入文本进行预处理\n",
    "    inputs = tokenizer(example[\"text\"], return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    \n",
    "    # 将输入数据移动到与模型相同的设备\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    # 使用模型进行预测\n",
    "    with torch.no_grad():\n",
    "        outputs = finetuned_model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=10, num_return_sequences=1)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # 判断生成的文本属于哪个类别\n",
    "    if label_map[0] in generated_text:\n",
    "        predicted_label = 0\n",
    "    elif label_map[1] in generated_text:\n",
    "        predicted_label = 1\n",
    "    else:\n",
    "        predicted_label = None  # 如果生成的文本不包含任何一个标签,则不考虑这个样本\n",
    "    \n",
    "    return {\"text\": example[\"text\"], \"label\": example[\"label\"], \"predicted_label\": predicted_label}\n",
    "\n",
    "# 在测试集上进行预测\n",
    "predictions = []\n",
    "labels = []\n",
    "total_examples = len(test_ds)\n",
    "print(f\"Total examples: {total_examples}\")\n",
    "\n",
    "progress_bar = tqdm(test_ds, desc=\"Evaluating\")\n",
    "\n",
    "for example in progress_bar:\n",
    "    processed_example = preprocess_and_label(example)\n",
    "    if processed_example[\"predicted_label\"] is not None:  # 只考虑有效的预测\n",
    "        predictions.append(processed_example[\"predicted_label\"])\n",
    "        labels.append(processed_example[\"label\"])\n",
    "\n",
    "# 打印最终的评估指标\n",
    "print(f\"Accuracy: {accuracy_score(labels, predictions):.4f}\")\n",
    "print(f\"F1 score: {f1_score(labels, predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827f49d-0408-4d1d-bf65-9e46f077723d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
