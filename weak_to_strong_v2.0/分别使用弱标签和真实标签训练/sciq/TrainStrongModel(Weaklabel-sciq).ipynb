{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53446a9-2ae4-415d-8293-c50d7119e994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U transformers accelerate datasets bitsandbytes einops wandb trl peft scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c8a421-e84c-4bb1-9b6e-48b58d95abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"labeled_dataset.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c54c35d-6a96-4906-9eb1-33a4236dc713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support', 'answer_option', 'label'],\n",
       "    num_rows: 30716\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697c07ac-31ce-4b61-b591-812772c41f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the main form of energy storage in plants?',\n",
       " 'distractor3': 'liquid',\n",
       " 'distractor1': 'nitrogen',\n",
       " 'distractor2': 'dioxide',\n",
       " 'correct_answer': 'starch',\n",
       " 'support': 'Many simple sugars can combine by repeated condensation reactions until a very large molecule is formed. A polysaccharide is a complex carbohydrate polymer formed from the linkage of many monosaccharide monomers. One of the best known polysaccharides is starch, the main form of energy storage in plants. Starch is a staple in most human diets. Foods such as corn, potatoes, rice, and wheat have high starch contents. Starch is made of glucose monomers and occurs in both straight-chain and branched forms. Amylose is the straight-chain form and consists of hundreds of linked glucose molecules. The branched form of starch is called amylopectin. In the small intestine, starch is hydrolyzed to form glucose. The glucose can then be converted to biochemical energy or stored for later use.',\n",
       " 'answer_option': 'nitrogen',\n",
       " 'label': -1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c54472-3408-4af8-a058-c8e95ccba928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将txt和label字段合并为一个整体\n",
    "def merge_fields(example):\n",
    "    text = example['question']\n",
    "    distractor1 = example['distractor1']\n",
    "    distractor2 = example['distractor2']\n",
    "    distractor3 = example['distractor3']\n",
    "    correct_answer = example['correct_answer']\n",
    "    support = example['support']\n",
    "    answer_option = example['answer_option']\n",
    "    label = example['label']\n",
    "    merged_input = f\"Text: {text}\\nDistractor1: {distractor1}\\nDistractor2: {distractor2}\\nDistractor1: {distractor3}\\ncorrect_answer: {correct_answer}\\nsupport: {support}\\nanswer_option: {answer_option}\\nLabel: {label}\"\n",
    "    return {'merged_input': merged_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9c9ef33-d3ad-4d24-8483-4cd24cfaf6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0750f834d0f24fefba9a06a494486cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30716 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(merge_fields, remove_columns=['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support', 'answer_option', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f808ae-b207-4550-bc66-50d805ffed2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'merged_input': 'Text: What is the main form of energy storage in plants?\\nDistractor1: nitrogen\\nDistractor2: dioxide\\nDistractor1: liquid\\ncorrect_answer: starch\\nsupport: Many simple sugars can combine by repeated condensation reactions until a very large molecule is formed. A polysaccharide is a complex carbohydrate polymer formed from the linkage of many monosaccharide monomers. One of the best known polysaccharides is starch, the main form of energy storage in plants. Starch is a staple in most human diets. Foods such as corn, potatoes, rice, and wheat have high starch contents. Starch is made of glucose monomers and occurs in both straight-chain and branched forms. Amylose is the straight-chain form and consists of hundreds of linked glucose molecules. The branched form of starch is called amylopectin. In the small intestine, starch is hydrolyzed to form glucose. The glucose can then be converted to biochemical energy or stored for later use.\\nanswer_option: nitrogen\\nLabel: -1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87db65ad-0f54-4b9f-9916-e9ded838c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_name = 'gpt2-medium'\n",
    "\n",
    "#bnb_config = BitsAndBytesConfig(\n",
    "    #load_in_4bit=True,\n",
    "    #bnb_4bit_quant_type='nf4',\n",
    "    #bnb_4bit_compute_dtype=torch.float16,\n",
    "#)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='auto',\n",
    "    #quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72d0927b-421b-4d54-b06a-891f964e3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7377d9c7-6e0c-4831-a8c2-4c0519e3482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = './results5'\n",
    "per_device_train_batch_size = 4\n",
    "gradient_accumulation_steps = 4\n",
    "optim = 'paged_adamw_32bit'\n",
    "save_steps = 1000\n",
    "logging_steps = 10\n",
    "learning_rate = 2e-5\n",
    "max_grad_norm = 0.3\n",
    "max_steps = 1000\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = 'constant'\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    #fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d3a2ff-4e9a-4300-aadd-e470596ef9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17aac04564504e24b116c9756d14e8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30716 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "#from accelerate import Accelerator\n",
    "\n",
    "max_seq_length = 1024\n",
    "\n",
    "#accelerator = Accelerator()\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    #peft_config=peft_config,\n",
    "    dataset_text_field='merged_input',\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "\n",
    "for name, module in trainer.model.named_modules():\n",
    "    if 'norm' in name:\n",
    "        module = module.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa6b5b-fe25-4db4-ac30-8611b87610bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms1820587\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/wandb/run-20240517_071942-yd4oeira</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s1820587/huggingface/runs/yd4oeira' target=\"_blank\">autumn-puddle-196</a></strong> to <a href='https://wandb.ai/s1820587/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s1820587/huggingface' target=\"_blank\">https://wandb.ai/s1820587/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s1820587/huggingface/runs/yd4oeira' target=\"_blank\">https://wandb.ai/s1820587/huggingface/runs/yd4oeira</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='401' max='5757' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 401/5757 03:02 < 40:47, 2.19 it/s, Epoch 0.21/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.790800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.342800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.984700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.552500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.386800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.861700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.551200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.470600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.368900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.996800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.788500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.582700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.400400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.335100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.619400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.403900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.929400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.761700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.507400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.416800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.249500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.914700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.716800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.488600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.302900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.324100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.923400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.742800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.338500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.270100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.912200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.497900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f60180-5f6c-4936-abeb-582f79975406",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
    "model_to_save.save_pretrained('gpt2medium_strong_model_outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d14487-b82c-4d42-93c3-5746f5c67522",
   "metadata": {},
   "source": [
    "# 使用测试集对微调后的模型进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b827f49d-0408-4d1d-bf65-9e46f077723d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15f954c91e844b3a4095e45512757d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4000/4000 [08:08<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7391\n",
      "F1 score: 0.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import logging\n",
    "\n",
    "# 设置日志级别为ERROR, 以抑制警告信息\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# 加载微调后的tokenizer和模型\n",
    "model_path = \"gpt2medium_strong_model_outputs1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2-medium')\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto', trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "finetuned_model.to(device)\n",
    "\n",
    "# 定义分类标签\n",
    "label_map = {0: \" No\", 1: \" Yes\"}\n",
    "\n",
    "# 加载测试数据集\n",
    "test_ds = load_dataset(\"json\", data_files=\"test_ds.jsonl\", split='train')\n",
    "\n",
    "# 对数据集进行预处理和打标签\n",
    "def preprocess_and_label(example):\n",
    "    # 将所有特征拼接为一个输入文本\n",
    "    input_text = f\"Question: {example['question']} Distractor3: {example['distractor3']} Distractor1: {example['distractor1']} Distractor2: {example['distractor2']} Correct Answer: {example['correct_answer']} Support: {example['support']} Answer Option: {example['answer_option']}\"\n",
    "    \n",
    "    # 对输入文本进行预处理\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    # 将输入数据移动到与模型相同的设备\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    with torch.no_grad():\n",
    "        outputs = finetuned_model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=10, num_return_sequences=1)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # 判断生成的文本属于哪个类别\n",
    "    if label_map[0] in generated_text:\n",
    "        predicted_label = 0\n",
    "    elif label_map[1] in generated_text:\n",
    "        predicted_label = 1\n",
    "    else:\n",
    "        predicted_label = None  # 如果生成的文本不包含任何一个标签，则不考虑这个样本\n",
    "\n",
    "    return {\"text\": input_text, \"label\": example[\"label\"], \"predicted_label\": predicted_label}\n",
    "\n",
    "# 在测试集上进行预测\n",
    "predictions = []\n",
    "labels = []\n",
    "total_examples = len(test_ds)\n",
    "print(f\"Total examples: {total_examples}\")\n",
    "\n",
    "progress_bar = tqdm(test_ds, desc=\"Evaluating\")\n",
    "for example in progress_bar:\n",
    "    processed_example = preprocess_and_label(example)\n",
    "    if processed_example[\"predicted_label\"] is not None:\n",
    "        # 只考虑有效的预测\n",
    "        predictions.append(processed_example[\"predicted_label\"])\n",
    "        labels.append(processed_example[\"label\"])\n",
    "\n",
    "# 打印最终的评估指标\n",
    "print(f\"Accuracy: {accuracy_score(labels, predictions):.4f}\")\n",
    "print(f\"F1 score: {f1_score(labels, predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43a6e69-5c2b-4be2-80d7-6f1af841f657",
   "metadata": {},
   "source": [
    "# 使用测试集对原始模型进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d331521-92d3-429e-bf13-3ffe98a50a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import logging\n",
    "\n",
    "# 设置日志级别为ERROR, 以抑制警告信息\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# 加载微调后的tokenizer和模型\n",
    "model_path = \"gpt2-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2-medium')\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto', trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "finetuned_model.to(device)\n",
    "\n",
    "# 定义分类标签\n",
    "label_map = {0: \" No\", 1: \" Yes\"}\n",
    "\n",
    "# 加载测试数据集\n",
    "#test_ds = load_dataset(\"json\", data_files=\"test_ds.jsonl\", split='train')\n",
    "\n",
    "# 对数据集进行预处理和打标签\n",
    "def preprocess_and_label(example):\n",
    "    # 将所有特征拼接为一个输入文本\n",
    "    input_text = f\"Question: {example['question']} Distractor3: {example['distractor3']} Distractor1: {example['distractor1']} Distractor2: {example['distractor2']} Correct Answer: {example['correct_answer']} Support: {example['support']} Answer Option: {example['answer_option']}\"\n",
    "    \n",
    "    # 对输入文本进行预处理\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    # 将输入数据移动到与模型相同的设备\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    with torch.no_grad():\n",
    "        outputs = finetuned_model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=10, num_return_sequences=1)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # 判断生成的文本属于哪个类别\n",
    "    if label_map[0] in generated_text:\n",
    "        predicted_label = 0\n",
    "    elif label_map[1] in generated_text:\n",
    "        predicted_label = 1\n",
    "    else:\n",
    "        predicted_label = None  # 如果生成的文本不包含任何一个标签，则不考虑这个样本\n",
    "\n",
    "    return {\"text\": input_text, \"label\": example[\"label\"], \"predicted_label\": predicted_label}\n",
    "\n",
    "# 在测试集上进行预测\n",
    "predictions = []\n",
    "labels = []\n",
    "total_examples = len(test_ds)\n",
    "print(f\"Total examples: {total_examples}\")\n",
    "\n",
    "progress_bar = tqdm(test_ds, desc=\"Evaluating\")\n",
    "for example in progress_bar:\n",
    "    processed_example = preprocess_and_label(example)\n",
    "    if processed_example[\"predicted_label\"] is not None:\n",
    "        # 只考虑有效的预测\n",
    "        predictions.append(processed_example[\"predicted_label\"])\n",
    "        labels.append(processed_example[\"label\"])\n",
    "\n",
    "# 打印最终的评估指标\n",
    "print(f\"Accuracy: {accuracy_score(labels, predictions):.4f}\")\n",
    "print(f\"F1 score: {f1_score(labels, predictions):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
